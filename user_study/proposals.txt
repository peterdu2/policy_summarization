Position sets:
	Position set 1:
		dsrnn1	['14000.pt', '20600.pt']
  		dsrnn3  ['20600.pt', '30800.pt']
  		dsrnn5  ['14000.pt', '30800.pt']

  	Position set 4:
 		dsrnn12	['14000.pt', '20600.pt']
  		dsrnn13	['20600.pt', '30800.pt']
  		dsrnn14	['14000.pt', '30800.pt']

- Divide each position set into 3 policies
	- Each policy: 6 trajectory examples (top 3 from each AST tree)
	- 3 x 6 = 18 examples per position set
	- Match with random sample trajectory examples
		- 6 samples for each policy 

User study groupings:
	- 3 position sets (PS1, PS4, PS5->tbd)
	- 18 AST examples per position set
		- 6 per policy
	- 18 random examples per position set
		- 6 per policy 

How to split users:
	1) Split per position set
		- Each user gets 1 position set
		- Shown random set -> asked to rank policies
		- Shown AST set -> asked to rank policies
		- Total = 36 trajectories 
	2) Split per random/AST
		- Each user shown all 3 position sets for either AST or random
		- Total = 18 x 3 = 44 trajectories 
		- Split into stages (PS1, PS2, PS3) -> ask for ranking at end
		- May be too many examples 
	3) Split per random/AST
		- Show each user one position set
		- n users per position set
		- need 3n users for AST, 3n users for random

EXPERIMENT 1: (Ranking 3 policies)
Data collection:
	- policy ranking (absolute ordering)
	- Need some sort of scale for confidence/ranking of separation of policies
	Candidates:
		- Semantic differential questions:
			The difference between the lowest ranked policy and middle ranked policy is:
			very small ........................................... very large

			The difference between the middle ranked policy and highest ranked policy is:
			very small ........................................... very large

		- Likart scale questions:
			It was easy to distinguish between the lowest ranked policy and the middle ranked policy:
			strongly disagree, disagree, neither disagree nor agree, agree, strongly agree

			It was easy to distinguish between the middle ranked policy and the highest ranked policy:
			strongly disagree, disagree, neither disagree nor agree, agree, strongly agree

EXPERIMENT 2: (Ranking 2 policies):
Data collection:
	- Show each person three scenarios (AB, BC, AC) and ask them to select the policy they think is best in 
	  each pair. 
	- Ask for confidence of rating 
	- Use different human position set than Experiment 1
	- Rename policies 
	- Desired data: 
		- Accuracy (how many times do users label correct policy in pair)
		- Confidence (how confident are users in their labels)


Final Position Sets:
  Human position set 8 (Collision Reward = 0):
  Reward: End episode if one policy reaches goal (goal_mode = REACHGOAL)
          Scale separatation reward at goal by alpha = 100 (same as terminal condition)
  dsrnn24  ['14000.pt', '20600.pt']
  dsrnn25  ['20600.pt', '34400.pt']
  dsrnn26  ['14000.pt', '34400.pt']

  Human position set 10 (Collision Reward = 0):
  Reward: End episode if one policy reaches goal (goal_mode = REACHGOAL)
          Scale separatation reward at goal by alpha = 100 (same as terminal condition)
  dsrnn30  ['14000.pt', '20600.pt']
  dsrnn31  ['20600.pt', '34400.pt']
  dsrnn32  ['14000.pt', '34400.pt']

Naming Map:
	HPS8 (AST):
		14000.pt: Robot 2
		20600.pt: Robot 3
		34400.pt: Robot 1
	HPS8 (Random):
		14000.pt: Robot 1
		20600.pt: Robot 3
		34400.pt: Robot 2

	HPS10 (AST):
		14000.pt: Robot 1
		20600.pt: Robot 3
		34400.pt: Robot 2
	HPS10 (Random):
		14000.pt: Robot 3
		20600.pt: Robot 1
		34400.pt: Robot 2


Survey orderings (Set 1):
Task 1 Set 1: Random	HPS8	Robot 1: 14000.pt, Robot 2: 34400.pt, Robot 3: 20600.pt
Task 1 Set 2: AST		HPS8	Robot 1: 34400.pt, Robot 2: 14000.pt, Robot 3: 20600.pt

Task 2 V1: AST			HPS10	Robot 1: 14000.pt, Robot 2: 34400.pt
Task 2 V2: Random		HPS10	Robot 1: 20600.pt, Robot 2: 34400.pt
Task 2 V3: Random		HPS10	Robot 2: 34400.pt, Robot 3: 14000.pt
Task 2 V4: AST			HPS10	Robot 2: 34400.pt, Robot 3: 20600.pt
Task 2 V5: AST			HPS10	Robot 1: 14000.pt, Robot 3: 20600.pt
Task 2 V6: Random		HPS10	Robot 1: 20600.pt, Robot 3: 14000.pt

Survey orderings (Set 2):
Task 1 Set 1: Random	HPS10	Robot 1: 20600.pt, Robot 2: 34400.pt, Robot 3: 14000.pt
Task 1 Set 2: AST		HPS10	Robot 1: 14000.pt, Robot 2: 34400.pt, Robot 3: 20600.pt

Task 2 V1: AST			HPS8	Robot 1: 34400.pt, Robot 2: 14000.pt
Task 2 V2: Random		HPS8	Robot 1: 14000.pt, Robot 2: 34400.pt
Task 2 V3: Random		HPS8	Robot 2: 34400.pt, Robot 3: 20600.pt
Task 2 V4: AST			HPS8	Robot 2: 14000.pt, Robot 3: 20600.pt
Task 2 V5: AST			HPS8	Robot 1: 34400.pt, Robot 3: 20600.pt
Task 2 V6: Random		HPS8	Robot 1: 14000.pt, Robot 3: 20600.pt
